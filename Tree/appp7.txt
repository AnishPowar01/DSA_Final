import org.apache.spark.sql.*;
import org.apache.spark.sql.types.*;
import static org.apache.spark.sql.functions.*;
import java.util.*;

public class DynamicTableSplitter {
    public static class TableSet {
        public final Dataset<Row> mainTable;
        public final Map<String, Dataset<Row>> childTables;
        public final Dataset<Row> errorRecords;

        public TableSet(Dataset<Row> mainTable, Map<String, Dataset<Row>> childTables, Dataset<Row> errorRecords) {
            this.mainTable = mainTable;
            this.childTables = childTables;
            this.errorRecords = errorRecords;
        }
    }

    private static class FieldInfo {
        final String path;
        final String name;
        final DataType dataType;
        final boolean isArray;
        final boolean isStruct;

        FieldInfo(String path, String name, DataType dataType) {
            this.path = path;
            this.name = name;
            this.dataType = dataType;
            this.isArray = dataType instanceof ArrayType;
            this.isStruct = isArray ? 
                ((ArrayType) dataType).elementType() instanceof StructType :
                dataType instanceof StructType;
        }
    }

    public static TableSet splitTables(Dataset<Row> dataset, String mainTableName, List<String> mainKeyColumns) {
        // First, validate and collect error records
        Dataset<Row> validatedDF = validateDataTypes(dataset);
        Dataset<Row> errorRecords = getErrorRecords(dataset, validatedDF, mainKeyColumns);
        
        // Convert to JSON and back to normalize the structure
        Dataset<Row> jsonDF = validatedDF.select(to_json(struct("*")).as("json_data"));
        Dataset<Row> parsedDF = jsonDF.select(from_json(col("json_data"), dataset.schema()).as("parsed_data"))
                                    .select("parsed_data.*");

        // Get all nested fields that need to be processed
        List<FieldInfo> fieldsToProcess = findNestedFields(dataset.schema(), "");
        
        Map<String, Dataset<Row>> childTables = new HashMap<>();
        Dataset<Row> mainTable = parsedDF;

        // Process each nested field
        for (FieldInfo field : fieldsToProcess) {
            String tableName = createTableName(mainTableName, field.path);
            Dataset<Row> childTable = createChildTable(
                mainTable, 
                field, 
                mainKeyColumns,
                getParentSeqColumns(field.path)
            );

            childTables.put(tableName, childTable);
            mainTable = mainTable.drop(field.name);
        }

        return new TableSet(mainTable, childTables, errorRecords);
    }

    private static Dataset<Row> validateDataTypes(Dataset<Row> df) {
        // Create a validated copy of the DataFrame
        Dataset<Row> validatedDF = df;
        
        // Get the schema
        StructType schema = df.schema();
        
        // Validate each field
        for (StructField field : schema.fields()) {
            if (field.dataType() instanceof ArrayType) {
                // Handle array fields
                validatedDF = validatedDF.withColumn(field.name(),
                    when(array_contains(schema_of_json(to_json(col(field.name()))), "ARRAY"), 
                        col(field.name()))
                    .otherwise(array())
                );
            }
        }
        
        return validatedDF;
    }

    private static Dataset<Row> getErrorRecords(
            Dataset<Row> originalDF, 
            Dataset<Row> validatedDF, 
            List<String> keyColumns) {
        
        // Select key columns and problematic fields
        Column[] selectCols = new Column[keyColumns.size() + 1];
        int i = 0;
        for (String keyCol : keyColumns) {
            selectCols[i++] = col(keyCol);
        }
        
        // Add an error_info column
        selectCols[i] = struct(
            lit("data_type_mismatch").as("error_type"),
            current_timestamp().as("error_timestamp")
        ).as("error_info");
        
        // Find records that were modified during validation
        Dataset<Row> errorDF = originalDF.except(validatedDF)
            .select(selectCols);
        
        return errorDF;
    }

    private static List<FieldInfo> findNestedFields(StructType schema, String parentPath) {
        List<FieldInfo> fields = new ArrayList<>();
        
        for (StructField field : schema.fields()) {
            String currentPath = parentPath.isEmpty() ? field.name() : parentPath + "." + field.name();
            
            if (field.dataType() instanceof ArrayType) {
                ArrayType arrayType = (ArrayType) field.dataType();
                if (arrayType.elementType() instanceof StructType) {
                    fields.add(new FieldInfo(currentPath, field.name(), field.dataType()));
                    fields.addAll(findNestedFields((StructType) arrayType.elementType(), currentPath));
                }
            } else if (field.dataType() instanceof StructType) {
                fields.add(new FieldInfo(currentPath, field.name(), field.dataType()));
                fields.addAll(findNestedFields((StructType) field.dataType(), currentPath));
            }
        }
        
        return fields;
    }

    private static String createTableName(String mainTableName, String fieldPath) {
        return mainTableName + "_" + fieldPath.replace(".", "_");
    }

    private static List<String> getParentSeqColumns(String path) {
        List<String> seqColumns = new ArrayList<>();
        String[] parts = path.split("\\.");
        StringBuilder currentPath = new StringBuilder();
        
        for (int i = 0; i < parts.length - 1; i++) {
            if (currentPath.length() > 0) {
                currentPath.append("_");
            }
            currentPath.append(parts[i]);
            seqColumns.add("seq_" + currentPath.toString());
        }
        
        return seqColumns;
    }

    private static Dataset<Row> createChildTable(
            Dataset<Row> parentTable,
            FieldInfo field,
            List<String> mainKeyColumns,
            List<String> parentSeqColumns
    ) {
        // Prepare columns to select
        List<Column> selectColumns = new ArrayList<>();
        
        // Add main key columns
        for (String keyColumn : mainKeyColumns) {
            selectColumns.add(col(keyColumn));
        }
        
        // Add parent sequence columns
        for (String seqColumn : parentSeqColumns) {
            selectColumns.add(col(seqColumn));
        }

        // Create child table
        Dataset<Row> childTable;
        if (field.isArray) {
            // Handle array of structs with null/type validation
            selectColumns.add(
                when(col(field.path).isNotNull() && 
                     array_contains(schema_of_json(to_json(col(field.path))), "ARRAY"),
                    explode_outer(col(field.path)))
                .otherwise(lit(null))
                .as(field.name + "_exploded")
            );
            
            childTable = parentTable.select(selectColumns.toArray(new Column[0]));
            
            if (field.dataType instanceof ArrayType && 
                ((ArrayType) field.dataType).elementType() instanceof StructType) {
                StructType structType = (StructType) ((ArrayType) field.dataType).elementType();
                for (StructField structField : structType.fields()) {
                    if (!(structField.dataType() instanceof ArrayType) && 
                        !(structField.dataType() instanceof StructType)) {
                        childTable = childTable.withColumn(
                            structField.name(),
                            col(field.name + "_exploded" + "." + structField.name())
                        );
                    }
                }
            }
            childTable = childTable.drop(field.name + "_exploded");
        } else {
            // Handle struct
            selectColumns.add(col(field.path));
            childTable = parentTable.select(selectColumns.toArray(new Column[0]));
            
            if (field.dataType instanceof StructType) {
                StructType structType = (StructType) field.dataType;
                for (StructField structField : structType.fields()) {
                    if (!(structField.dataType() instanceof ArrayType) && 
                        !(structField.dataType() instanceof StructType)) {
                        childTable = childTable.withColumn(
                            structField.name(),
                            col(field.name + "." + structField.name())
                        );
                    }
                }
            }
            childTable = childTable.drop(field.name);
        }

        // Add sequence column for this level
        String seqColumnName = "seq_" + field.path.replace(".", "_");
        childTable = childTable.withColumn(seqColumnName, monotonically_increasing_id());

        return childTable;
    }
}
